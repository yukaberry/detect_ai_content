{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/yuka/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/yuka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/yuka/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/yuka/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/yuka/.pyenv/versions/detect_ai_content/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/yuka/.pyenv/versions/detect_ai_content/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:47:11.454063: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-14 15:47:11.467918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731595631.485297   46336 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731595631.490226   46336 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 15:47:11.510344: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:47:26.758540: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.config.experimental.list_physical_devices(GPU):[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuka/.pyenv/versions/detect_ai_content/lib/python3.10/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "[nltk_data] Downloading package punkt to /home/yuka/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/yuka/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "\n",
    "from detect_ai_content.params import *\n",
    "\n",
    "# from detect_ai_content.ml_logic.for_texts.using_ml_features.TrueNetTextLogisticRegression import TrueNetTextLogisticRegression\n",
    "# from detect_ai_content.ml_logic.for_texts.using_ml_features.TrueNetTextTfidfNaiveBayesClassifier import TrueNetTextTfidfNaiveBayesClassifier\n",
    "# from detect_ai_content.ml_logic.for_texts.using_ml_features.TrueNetTextDecisionTreeClassifier import TrueNetTextDecisionTreeClassifier\n",
    "# from detect_ai_content.ml_logic.for_texts.using_ml_features.TrueNetTextSVC import TrueNetTextSVC\n",
    "# from detect_ai_content.ml_logic.for_texts.using_ml_features.TrueNetTextKNeighborsClassifier import TrueNetTextKNeighborsClassifier\n",
    "# from detect_ai_content.ml_logic.for_texts.using_ml_features.TrueNetTextUsingBERTMaskedPredictions import TrueNetTextUsingBERTMaskedPredictions\n",
    "\n",
    "from detect_ai_content.ml_logic.preprocess import preprocess\n",
    "from detect_ai_content.ml_logic.data import get_enriched_df\n",
    "\n",
    "from detect_ai_content.ml_logic.for_texts.XGB import XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_enriched_df(purpose=\"test\")\n",
    "df=df.head(5)\n",
    "y_test = df['generated']\n",
    "# X_test_processed = preprocess(data=df, auto_enrich=False)\n",
    "\n",
    "# TrueNetTextTfidfNaiveBayesClassifier_model = TrueNetTextTfidfNaiveBayesClassifier()._load_model(stage=\"Staging\")\n",
    "# TrueNetTextLogisticRegression_model = TrueNetTextLogisticRegression()._load_model(stage=\"staging\")\n",
    "# TrueNetTextDecisionTreeClassifier_model = TrueNetTextDecisionTreeClassifier()._load_model(stage=\"staging\")\n",
    "# TrueNetTextKNeighborsClassifier_model = TrueNetTextKNeighborsClassifier()._load_model(stage=\"staging\")\n",
    "# TrueNetTextSVC_model = TrueNetTextSVC()._load_model(stage=\"staging\")\n",
    "# TrueNetTextUsingBERTMaskedPredictions_model = TrueNetTextUsingBERTMaskedPredictions()._load_model(stage=\"staging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGB()\n",
    "model = xgb.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopwords_ratio</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "      <th>repetition_ratio</th>\n",
       "      <th>dependency_ratio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>pos__ratio</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513089</td>\n",
       "      <td>0.094241</td>\n",
       "      <td>0.091623</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.094241</td>\n",
       "      <td>1.002618</td>\n",
       "      <td>3.829843</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>80.31</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.398773</td>\n",
       "      <td>0.119632</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.110429</td>\n",
       "      <td>1.006135</td>\n",
       "      <td>4.457055</td>\n",
       "      <td>0.493865</td>\n",
       "      <td>41.70</td>\n",
       "      <td>15.3</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.433898</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.081356</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>1.010169</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.498305</td>\n",
       "      <td>46.81</td>\n",
       "      <td>14.7</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408759</td>\n",
       "      <td>0.131387</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.131387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.062044</td>\n",
       "      <td>0.427007</td>\n",
       "      <td>85.59</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.489971</td>\n",
       "      <td>0.054441</td>\n",
       "      <td>0.143266</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>0.988539</td>\n",
       "      <td>4.255014</td>\n",
       "      <td>0.282235</td>\n",
       "      <td>68.10</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stopwords_ratio  punctuation_ratio  repetition_ratio  dependency_ratio  \\\n",
       "0         0.513089           0.094241          0.091623          0.150000   \n",
       "1         0.398773           0.119632          0.049080          0.166667   \n",
       "2         0.433898           0.098305          0.081356          1.100000   \n",
       "3         0.408759           0.131387          0.083942          0.272727   \n",
       "4         0.489971           0.054441          0.143266          0.939394   \n",
       "\n",
       "   spelling_errors_ratio  pos__ratio  avg_word_length  lexical_diversity  \\\n",
       "0               0.094241    1.002618         3.829843           0.413613   \n",
       "1               0.110429    1.006135         4.457055           0.493865   \n",
       "2               0.091525    1.010169         4.600000           0.498305   \n",
       "3               0.131387    1.000000         4.062044           0.427007   \n",
       "4               0.047278    0.988539         4.255014           0.282235   \n",
       "\n",
       "   flesch_reading_ease  smog_index  flesch_kincaid_grade  sentiment  \n",
       "0                80.31         8.0                   6.1         -1  \n",
       "1                41.70        15.3                  12.7          1  \n",
       "2                46.81        14.7                  12.8         -1  \n",
       "3                85.59         6.9                   4.1         -1  \n",
       "4                68.10        11.3                   8.7         -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = xgb.get_internal_features(text=df)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_preds = model.predict(dfs)\n",
    "xgb_preds\n",
    "# TrueNetTextLogisticRegression_preds = TrueNetTextLogisticRegression_model.predict(X_test_processed)\n",
    "# TrueNetTextDecisionTreeClassifier_preds = TrueNetTextDecisionTreeClassifier_model.predict(X_test_processed)\n",
    "# TrueNetTextKNeighborsClassifier_preds = TrueNetTextKNeighborsClassifier_model.predict(X_test_processed)\n",
    "# TrueNetTextSVC_preds = TrueNetTextSVC_model.predict(X_test_processed)\n",
    "# TrueNetTextTfidfNaiveBayesClassifier_preds = TrueNetTextTfidfNaiveBayesClassifier_model.predict(df['text'])\n",
    "\n",
    "# X_BERT_processed = TrueNetTextUsingBERTMaskedPredictions.preprocess(data=df)\n",
    "# TrueNetTextUsingBERTMaskedPredictions_preds = TrueNetTextUsingBERTMaskedPredictions_model.predict(X_BERT_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9222422e-01, 7.7757854e-03],\n",
       "       [6.3657761e-05, 9.9993634e-01],\n",
       "       [2.4437904e-05, 9.9997556e-01],\n",
       "       [9.8029590e-01, 1.9704077e-02],\n",
       "       [9.9951053e-01, 4.8947602e-04]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_preds_proba = model.predict_proba(dfs)\n",
    "xgb_preds_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class 0 is on left  \n",
    "# class 1 is on the right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB  y_test\n",
       "0    0     0.0\n",
       "1    1     1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(data={\n",
    "    # 'LogisticRegression':TrueNetTextLogisticRegression_preds,\n",
    "    # 'DecisionTreeClassifier':TrueNetTextDecisionTreeClassifier_preds,\n",
    "    # 'KNeighborsClassifier':TrueNetTextKNeighborsClassifier_preds,\n",
    "    # 'SVC':TrueNetTextSVC_preds,\n",
    "    # 'BERTMaskedPredictions':TrueNetTextUsingBERTMaskedPredictions_preds,\n",
    "    # 'TfidfNaiveBayesClassifier': TrueNetTextTfidfNaiveBayesClassifier_preds,\n",
    "    'XGB':xgb_preds,\n",
    "    'y_test':y_test\n",
    "})\n",
    "predictions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   XGB  y_test\n",
       "0    0     0.0\n",
       "1    1     1.0\n",
       "2    1     1.0\n",
       "3    0     0.0\n",
       "4    0     0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['LogisticRegression_diff'] = predictions_df['LogisticRegression'] - predictions_df['y_test']\n",
    "predictions_df['DecisionTreeClassifier_diff'] = predictions_df['DecisionTreeClassifier'] - predictions_df['y_test']\n",
    "predictions_df['KNeighborsClassifier_diff'] = predictions_df['KNeighborsClassifier'] - predictions_df['y_test']\n",
    "predictions_df['SVC_diff'] = predictions_df['SVC'] - predictions_df['y_test']\n",
    "predictions_df['BERTMaskedPredictions_diff'] = predictions_df['BERTMaskedPredictions'] - predictions_df['y_test']\n",
    "predictions_df['TfidfNaiveBayesClassifier_diff'] = predictions_df['TfidfNaiveBayesClassifier'] - predictions_df['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['sum_diff'] = abs(predictions_df['LogisticRegression_diff']) + abs(predictions_df['DecisionTreeClassifier_diff']) + abs(predictions_df['KNeighborsClassifier_diff']) + abs(predictions_df['SVC_diff']) + abs(predictions_df['BERTMaskedPredictions_diff']) + abs(predictions_df['TfidfNaiveBayesClassifier_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=predictions_df, x='sum_diff');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439306358381503"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions_df['sum_diff'] < 2) / predictions_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>BERTMaskedPredictions</th>\n",
       "      <th>TfidfNaiveBayesClassifier</th>\n",
       "      <th>y_test</th>\n",
       "      <th>sum_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LogisticRegression  DecisionTreeClassifier  KNeighborsClassifier  SVC  \\\n",
       "275                 0.0                     0.0                   0.0  0.0   \n",
       "229                 0.0                     0.0                   0.0  0.0   \n",
       "66                  0.0                     0.0                   0.0  0.0   \n",
       "213                 0.0                     0.0                   0.0  0.0   \n",
       "118                 0.0                     0.0                   0.0  0.0   \n",
       "192                 1.0                     1.0                   1.0  1.0   \n",
       "149                 1.0                     1.0                   1.0  1.0   \n",
       "132                 1.0                     1.0                   1.0  1.0   \n",
       "294                 1.0                     1.0                   1.0  1.0   \n",
       "282                 0.0                     0.0                   0.0  0.0   \n",
       "255                 1.0                     1.0                   1.0  1.0   \n",
       "244                 0.0                     0.0                   0.0  0.0   \n",
       "227                 1.0                     1.0                   1.0  1.0   \n",
       "226                 1.0                     1.0                   1.0  1.0   \n",
       "218                 0.0                     0.0                   0.0  0.0   \n",
       "334                 1.0                     1.0                   1.0  1.0   \n",
       "63                  0.0                     0.0                   0.0  0.0   \n",
       "121                 0.0                     0.0                   0.0  0.0   \n",
       "69                  0.0                     0.0                   0.0  0.0   \n",
       "5                   1.0                     1.0                   1.0  0.0   \n",
       "160                 0.0                     1.0                   0.0  0.0   \n",
       "184                 0.0                     1.0                   0.0  1.0   \n",
       "101                 0.0                     1.0                   0.0  0.0   \n",
       "92                  0.0                     1.0                   0.0  0.0   \n",
       "90                  1.0                     0.0                   1.0  1.0   \n",
       "61                  1.0                     0.0                   0.0  0.0   \n",
       "305                 0.0                     0.0                   0.0  0.0   \n",
       "41                  0.0                     0.0                   1.0  0.0   \n",
       "32                  1.0                     0.0                   0.0  1.0   \n",
       "317                 1.0                     0.0                   0.0  0.0   \n",
       "16                  1.0                     0.0                   0.0  1.0   \n",
       "135                 1.0                     1.0                   0.0  0.0   \n",
       "257                 1.0                     0.0                   0.0  1.0   \n",
       "53                  1.0                     1.0                   0.0  1.0   \n",
       "148                 0.0                     0.0                   1.0  1.0   \n",
       "0                   1.0                     0.0                   0.0  1.0   \n",
       "\n",
       "     BERTMaskedPredictions  TfidfNaiveBayesClassifier  y_test  sum_diff  \n",
       "275                    0.0                        0.0     1.0       6.0  \n",
       "229                    0.0                        0.0     1.0       6.0  \n",
       "66                     0.0                        0.0     1.0       6.0  \n",
       "213                    0.0                        0.0     1.0       6.0  \n",
       "118                    0.0                        0.0     1.0       6.0  \n",
       "192                    1.0                        1.0     0.0       6.0  \n",
       "149                    1.0                        0.0     0.0       5.0  \n",
       "132                    1.0                        0.0     0.0       5.0  \n",
       "294                    1.0                        0.0     0.0       5.0  \n",
       "282                    0.0                        1.0     1.0       5.0  \n",
       "255                    1.0                        0.0     0.0       5.0  \n",
       "244                    1.0                        0.0     1.0       5.0  \n",
       "227                    1.0                        0.0     0.0       5.0  \n",
       "226                    1.0                        0.0     0.0       5.0  \n",
       "218                    0.0                        1.0     1.0       5.0  \n",
       "334                    0.0                        1.0     0.0       5.0  \n",
       "63                     0.0                        1.0     1.0       5.0  \n",
       "121                    0.0                        1.0     1.0       5.0  \n",
       "69                     0.0                        1.0     1.0       5.0  \n",
       "5                      1.0                        0.0     0.0       4.0  \n",
       "160                    0.0                        1.0     1.0       4.0  \n",
       "184                    0.0                        0.0     1.0       4.0  \n",
       "101                    0.0                        1.0     1.0       4.0  \n",
       "92                     1.0                        0.0     1.0       4.0  \n",
       "90                     1.0                        0.0     0.0       4.0  \n",
       "61                     0.0                        1.0     1.0       4.0  \n",
       "305                    1.0                        1.0     1.0       4.0  \n",
       "41                     0.0                        1.0     1.0       4.0  \n",
       "32                     1.0                        0.0     0.0       3.0  \n",
       "317                    1.0                        1.0     1.0       3.0  \n",
       "16                     1.0                        0.0     0.0       3.0  \n",
       "135                    1.0                        0.0     0.0       3.0  \n",
       "257                    1.0                        0.0     1.0       3.0  \n",
       "53                     0.0                        0.0     0.0       3.0  \n",
       "148                    1.0                        0.0     0.0       3.0  \n",
       "0                      1.0                        0.0     0.0       3.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[predictions_df['sum_diff'] > 2][['LogisticRegression', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'SVC','BERTMaskedPredictions','TfidfNaiveBayesClassifier', 'y_test', 'sum_diff']].sort_values(by=['sum_diff'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8764c6808ed96d2736f47875bfcd7b4e4bf38b212bb1fe2028409af633673231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
