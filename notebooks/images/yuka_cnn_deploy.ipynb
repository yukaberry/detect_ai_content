{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuka/code/yukaberry/detect_ai_content/detect_ai_content/ml_logic/for_images\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 18:26:46.965602: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59168</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">118,338</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59168\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │       \u001b[38;5;34m118,338\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,431</span> (482.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m123,431\u001b[0m (482.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,429</span> (482.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,429\u001b[0m (482.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('../../models/yukaberry/cnn_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = '0.jpg'\n",
    "img = Image.open(test_image)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(180, 180)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Loads and preprocesses an image.\n",
    "\n",
    "    Parameters:\n",
    "    - img_path (str): Path to the image file.\n",
    "    - target_size (tuple): Desired image size in pixels, e.g., (180, 180).\n",
    "\n",
    "    Returns:\n",
    "    - img_array (numpy.ndarray): Preprocessed image array ready for CNN input.\n",
    "    \"\"\"\n",
    "    # Load the image with the target size and ensure it's RGB\n",
    "    img = image.load_img(img_path, target_size=target_size, color_mode='rgb')\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # Optionally, expand dimensions to match the expected input shape for the model\n",
    "    # (e.g., (1, 180, 180, 3) for a single image)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Optionally, normalize the image data to [0, 1]\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.5254902 , 0.64705884, 0.83137256],\n",
       "         [0.5254902 , 0.64705884, 0.83137256],\n",
       "         [0.5254902 , 0.64705884, 0.83137256],\n",
       "         ...,\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ],\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ],\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ]],\n",
       "\n",
       "        [[0.5254902 , 0.64705884, 0.83137256],\n",
       "         [0.5254902 , 0.64705884, 0.83137256],\n",
       "         [0.5254902 , 0.64705884, 0.83137256],\n",
       "         ...,\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ],\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ],\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ]],\n",
       "\n",
       "        [[0.5254902 , 0.64705884, 0.83137256],\n",
       "         [0.5254902 , 0.64705884, 0.83137256],\n",
       "         [0.5254902 , 0.64705884, 0.83137256],\n",
       "         ...,\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ],\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ],\n",
       "         [0.52156866, 0.6117647 , 0.8745098 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5372549 , 0.7019608 , 0.8       ],\n",
       "         [0.5372549 , 0.7019608 , 0.8       ],\n",
       "         [0.5372549 , 0.7019608 , 0.8       ],\n",
       "         ...,\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ],\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ],\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ]],\n",
       "\n",
       "        [[0.5372549 , 0.7019608 , 0.8       ],\n",
       "         [0.5372549 , 0.7019608 , 0.8       ],\n",
       "         [0.5372549 , 0.7019608 , 0.8       ],\n",
       "         ...,\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ],\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ],\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ]],\n",
       "\n",
       "        [[0.5372549 , 0.7019608 , 0.8       ],\n",
       "         [0.5372549 , 0.7019608 , 0.8       ],\n",
       "         [0.5372549 , 0.7019608 , 0.8       ],\n",
       "         ...,\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ],\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ],\n",
       "         [0.42745098, 0.6666667 , 0.9137255 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_img = preprocess_image(test_image, target_size=(180, 180))\n",
    "pro_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49266428]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = model.predict(pro_img)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probabilities = np.argmax(pred_class, axis=1)\n",
    "predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# clean sample image data \n",
    "# predict \n",
    "# create api \n",
    "# test locap api \n",
    "# deploy locally \n",
    "# deploy to cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, metrics, callbacks, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 files belonging to 2 classes.\n",
      "Using 0 files for validation.\n"
     ]
    }
   ],
   "source": [
    "sample_data = 'sample/'\n",
    "sample_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  sample_data,\n",
    "  labels='inferred',\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(180, 180),\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE : file structure has to Be \n",
    "\n",
    "- sample \n",
    "    - FAKE \n",
    "        - x.jpg\n",
    "    - REAL \n",
    "        - xx.jpg \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FAKE', 'REAL']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 likely representing 'FAKE' and 1 representing 'REAL'. \n",
    "\n",
    "sample_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 12:59:52.736597: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "sample = []\n",
    "sample_target = []\n",
    "\n",
    "for images, labels in sample_ds:\n",
    "    sample.append(images.numpy())\n",
    "    sample_target.append(labels.numpy())\n",
    "    \n",
    "sample = np.concatenate(sample, axis=0)\n",
    "sample_target = np.concatenate(sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 180, 180, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msample_target\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_target' is not defined"
     ]
    }
   ],
   "source": [
    "sample_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00215302, 0.00244521, 0.00270665],\n",
       "         [0.00215302, 0.00244521, 0.00270665],\n",
       "         [0.00215302, 0.00244521, 0.00270665],\n",
       "         ...,\n",
       "         [0.00279892, 0.00269127, 0.0028143 ],\n",
       "         [0.00279892, 0.00269127, 0.0028143 ],\n",
       "         [0.00279892, 0.00269127, 0.0028143 ]],\n",
       "\n",
       "        [[0.00215302, 0.00244521, 0.00270665],\n",
       "         [0.00215302, 0.00244521, 0.00270665],\n",
       "         [0.00215302, 0.00244521, 0.00270665],\n",
       "         ...,\n",
       "         [0.00279892, 0.00269127, 0.0028143 ],\n",
       "         [0.00279892, 0.00269127, 0.0028143 ],\n",
       "         [0.00279892, 0.00269127, 0.0028143 ]],\n",
       "\n",
       "        [[0.00215302, 0.00244521, 0.00270665],\n",
       "         [0.00215302, 0.00244521, 0.00270665],\n",
       "         [0.00215302, 0.00244521, 0.00270665],\n",
       "         ...,\n",
       "         [0.00279892, 0.00269127, 0.0028143 ],\n",
       "         [0.00279892, 0.00269127, 0.0028143 ],\n",
       "         [0.00279892, 0.00269127, 0.0028143 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00138408, 0.0012303 , 0.00109189],\n",
       "         [0.00138408, 0.0012303 , 0.00109189],\n",
       "         [0.00138408, 0.0012303 , 0.00109189],\n",
       "         ...,\n",
       "         [0.00075356, 0.00110727, 0.00095348],\n",
       "         [0.00075356, 0.00110727, 0.00095348],\n",
       "         [0.00075356, 0.00110727, 0.00095348]],\n",
       "\n",
       "        [[0.00138408, 0.0012303 , 0.00109189],\n",
       "         [0.00138408, 0.0012303 , 0.00109189],\n",
       "         [0.00138408, 0.0012303 , 0.00109189],\n",
       "         ...,\n",
       "         [0.00075356, 0.00110727, 0.00095348],\n",
       "         [0.00075356, 0.00110727, 0.00095348],\n",
       "         [0.00075356, 0.00110727, 0.00095348]],\n",
       "\n",
       "        [[0.00138408, 0.0012303 , 0.00109189],\n",
       "         [0.00138408, 0.0012303 , 0.00109189],\n",
       "         [0.00138408, 0.0012303 , 0.00109189],\n",
       "         ...,\n",
       "         [0.00075356, 0.00110727, 0.00095348],\n",
       "         [0.00075356, 0.00110727, 0.00095348],\n",
       "         [0.00075356, 0.00110727, 0.00095348]]],\n",
       "\n",
       "\n",
       "       [[[0.00206075, 0.00253749, 0.00326028],\n",
       "         [0.00206075, 0.00253749, 0.00326028],\n",
       "         [0.00206075, 0.00253749, 0.00326028],\n",
       "         ...,\n",
       "         [0.00204537, 0.00241446, 0.00339869],\n",
       "         [0.00204537, 0.00241446, 0.00339869],\n",
       "         [0.00204537, 0.00241446, 0.00339869]],\n",
       "\n",
       "        [[0.00206075, 0.00253749, 0.00326028],\n",
       "         [0.00206075, 0.00253749, 0.00326028],\n",
       "         [0.00206075, 0.00253749, 0.00326028],\n",
       "         ...,\n",
       "         [0.00204537, 0.00241446, 0.00339869],\n",
       "         [0.00204537, 0.00241446, 0.00339869],\n",
       "         [0.00204537, 0.00241446, 0.00339869]],\n",
       "\n",
       "        [[0.00206075, 0.00253749, 0.00326028],\n",
       "         [0.00206075, 0.00253749, 0.00326028],\n",
       "         [0.00206075, 0.00253749, 0.00326028],\n",
       "         ...,\n",
       "         [0.00204537, 0.00241446, 0.00339869],\n",
       "         [0.00204537, 0.00241446, 0.00339869],\n",
       "         [0.00204537, 0.00241446, 0.00339869]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0020915 , 0.00273741, 0.00312188],\n",
       "         [0.0020915 , 0.00273741, 0.00312188],\n",
       "         [0.0020915 , 0.00273741, 0.00312188],\n",
       "         ...,\n",
       "         [0.00167628, 0.00261438, 0.00358324],\n",
       "         [0.00167628, 0.00261438, 0.00358324],\n",
       "         [0.00167628, 0.00261438, 0.00358324]],\n",
       "\n",
       "        [[0.0020915 , 0.00273741, 0.00312188],\n",
       "         [0.0020915 , 0.00273741, 0.00312188],\n",
       "         [0.0020915 , 0.00273741, 0.00312188],\n",
       "         ...,\n",
       "         [0.00167628, 0.00261438, 0.00358324],\n",
       "         [0.00167628, 0.00261438, 0.00358324],\n",
       "         [0.00167628, 0.00261438, 0.00358324]],\n",
       "\n",
       "        [[0.0020915 , 0.00273741, 0.00312188],\n",
       "         [0.0020915 , 0.00273741, 0.00312188],\n",
       "         [0.0020915 , 0.00273741, 0.00312188],\n",
       "         ...,\n",
       "         [0.00167628, 0.00261438, 0.00358324],\n",
       "         [0.00167628, 0.00261438, 0.00358324],\n",
       "         [0.00167628, 0.00261438, 0.00358324]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = sample/255\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49185356],\n",
       "       [0.49184588]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.49185356)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intepretation of result \n",
    "\n",
    "- A value close to 0 : a higher confidence that the image is 'FAKE'\n",
    "- A value close to 1 : a higher confidence that the image is 'REAL'\n",
    "- A value around 0.5 : the model is unsure and doesn’t lean strongly towards either class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4918535649776459"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = float(model.predict(sample)[0][0])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample/FAKE/0.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43msample_input\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#img = sample_input.resize((180, 180))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(img)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "sample_input = \"sample/FAKE/0.jpg\"\n",
    "\n",
    "img = Image.open(BytesIO(sample_input))\n",
    "img = sample_input/255\n",
    "#img = sample_input.resize((180, 180))\n",
    "print(img)\n",
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('detect_ai_content')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4b38e1c70612509893b18ed4700a35d6c8bcccc35ae56a08892cbf2d8029aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
